{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd321d0c-9e95-4af0-9fa0-66646a9e5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import threading\n",
    "import time\n",
    "from queue import Queue\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63748827-7f4f-40f5-81fd-270dbe85d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "BASE_URL = \"https://jiji.com.et/api_web/v1/listing\"\n",
    "BASE_SITE = \"https://jiji.com.et\"\n",
    "CATEGORY_SLUG = \"vehicles\"\n",
    "NUM_WORKERS = 7\n",
    "DELAY_SECONDS = 2\n",
    "LSMID = \"1768997666323\"\n",
    "date = datetime.now()\n",
    "\n",
    "# --- Shared variables ---\n",
    "next_page = 1\n",
    "page_lock = threading.Lock()\n",
    "\n",
    "seen_guids = set()\n",
    "seen_lock = threading.Lock()\n",
    "\n",
    "all_products = []\n",
    "products_lock = threading.Lock()\n",
    "\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# --- Worker function ---\n",
    "def worker(worker_id):\n",
    "    global next_page\n",
    "    while not stop_event.is_set():\n",
    "        # Get the next page safely\n",
    "        with page_lock:\n",
    "            page = next_page\n",
    "            next_page += 1\n",
    "\n",
    "        params = {\n",
    "            \"slug\": CATEGORY_SLUG,\n",
    "            \"init_page\": \"true\" if page == 1 else \"false\",\n",
    "            \"page\": page,\n",
    "            \"webp\": \"false\",\n",
    "            \"lsmid\": LSMID\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(BASE_URL, params=params, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "        except Exception as e:\n",
    "            print(f\"[Worker {worker_id}] Request failed on page {page}: {e}\")\n",
    "            time.sleep(DELAY_SECONDS)\n",
    "            continue\n",
    "\n",
    "        adverts = data.get(\"adverts_list\", {}).get(\"adverts\", [])\n",
    "\n",
    "        # Stop if no adverts\n",
    "        if not adverts:\n",
    "            print(f\"[Worker {worker_id}] Page {page} has no adverts, stopping scraper\")\n",
    "            stop_event.set()\n",
    "            break\n",
    "\n",
    "        new_items = 0\n",
    "        for item in adverts:\n",
    "            guid = item.get(\"guid\")\n",
    "            if not guid:\n",
    "                continue\n",
    "\n",
    "            # Deduplicate\n",
    "            with seen_lock:\n",
    "                if guid in seen_guids:\n",
    "                    continue\n",
    "                seen_guids.add(guid)\n",
    "\n",
    "            images = [img.get(\"url\") for img in item.get(\"images\", []) if img.get(\"url\")]\n",
    "\n",
    "            product = {\n",
    "                \"title\": item.get(\"title\"),\n",
    "                \"category\": item.get(\"category_name\"),\n",
    "                \"category_id\": item.get(\"category_id\"),\n",
    "                \"description\": item.get(\"details\") or item.get(\"short_description\"),\n",
    "                \"price\": item.get(\"price_obj\", {}).get(\"value\"),\n",
    "                \"price_text\": item.get(\"price_title\"),\n",
    "                \"currency\": item.get(\"price_obj\", {}).get(\"currency\") or \"ETB\",\n",
    "                \"condition\": next((a.get(\"value\") for a in item.get(\"attrs\", []) if a.get(\"name\")==\"Condition\"), None),\n",
    "                \"region\": item.get(\"region_name\"),\n",
    "                \"region_id\": item.get(\"region_id\"),\n",
    "                \"city\": item.get(\"region_parent_name\"),\n",
    "                \"url\": urljoin(BASE_SITE, item.get(\"url\", \"\")),\n",
    "                \"guid\": guid,\n",
    "                \"images\": images,\n",
    "                \"count_images\": item.get(\"count_images\"),\n",
    "                \"user_id\": item.get(\"user_id\"),\n",
    "                \"status\": item.get(\"status\"),\n",
    "                \"scrape_date\": date\n",
    "            }\n",
    "\n",
    "            with products_lock:\n",
    "                all_products.append(product)\n",
    "            new_items += 1\n",
    "\n",
    "        print(f\"[Worker {worker_id}] Page {page} scraped, {new_items} new items\")\n",
    "        time.sleep(DELAY_SECONDS)\n",
    "\n",
    "# --- Start threads ---\n",
    "threads = []\n",
    "for i in range(NUM_WORKERS):\n",
    "    t = threading.Thread(target=worker, args=(i+1,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# --- Save results ---\n",
    "df = pd.DataFrame(all_products)\n",
    "df.to_json(\"jiji_vehicles.jsonl\", orient=\"records\", lines=True, index=False)\n",
    "print(f\"Scraping completed: {len(all_products)} products collected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
